### ðŸ“Š Foundations of Data Science

This section focuses on the fundamental statistical and mathematical concepts required in data science projects. These topics are essential for understanding, analyzing, and interpreting data before moving on to modeling.

---

#### ðŸ“Œ Descriptive Statistics & Probability

- **What is Statistics?**  
  Methods used to summarize and interpret data. Measures of central tendency (mean, median, mode) and measures of dispersion (variance, standard deviation) are introduced.

- **Concept of Probability**  
  Covers how to calculate the likelihood of events, probability rules, and combinations/permutations.

---

#### ðŸ“ˆ Probability Distributions

Various types of probability distributions are covered to understand how different data behaves:

- **Bernoulli & Binomial Distributions**  
  Used for binary outcomes such as success/failure.  
  *Example: Tossing a coin.*

- **Poisson Distribution**  
  Suitable for rare events in a fixed time frame.  
  *Example: Number of customers arriving per minute.*

- **Normal Distribution**  
  A common distribution in nature; symmetric around the mean.  
  Assumed in many machine learning algorithms.

- **Uniform Distribution**  
  All outcomes have equal probability.  
  *Example: Rolling a fair die.*

- **Log-Normal Distribution**  
  Used when the logarithm of the variable follows a normal distribution.  
  *Example: Financial return data.*

- **Pareto Distribution**  
  Related to the 80/20 rule.  
  *Example: Income distribution where a small group holds most of the wealth.*

---

#### ðŸ§  Central Limit Theorem

This theorem states that as the sample size increases, the sampling distribution of the mean approaches a normal distribution, regardless of the original distribution. It's a foundational concept for statistical inference.

---

#### ðŸ§ª Statistical Inference

Making conclusions about populations based on sample data using statistical tests:

- **Confidence Intervals**  
  Estimate the range in which the true population parameter lies with a certain level of confidence.

- **Hypothesis Testing**  
  Evaluate assumptions about a population.  
  Used to determine if differences between groups are statistically significant.

- **Z-Test & p-Value**  
  Used for large samples to compare means.  
  The p-value indicates whether observed differences are due to chance.

- **T-Test**  
  Applied to small samples to test the difference between two means.

- **Chi-Square Test**  
  Used to compare observed vs. expected frequencies in categorical data.

- **ANOVA (Analysis of Variance)**  
  Compares means across more than two groups.

- **Type I & Type II Errors**  
  Type I: Rejecting a true null hypothesis (false positive)  
  Type II: Failing to reject a false null hypothesis (false negative)

---

#### ðŸ“š Bayesâ€™ Theorem

Allows updating probabilities based on new evidence.  
It forms the basis of probabilistic models like the Naive Bayes classifier.

---

These foundational concepts form the core of statistical analysis in data science and provide the theoretical background necessary for advanced modeling and machine learning techniques.
